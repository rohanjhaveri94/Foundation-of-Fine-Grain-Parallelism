*******************************************************************************************************************************************

                                          # Foundation-of-Fine-Grain-Parallelism (ECE/CS 560)

*******************************************************************************************************************************************

Foundation of Fine Grain Parallelism (ECE/CS 560) is a cross listed course across Electrical and Computer Engineering and Computer Science departments at Colorado State University, Fort Collins taught by Dr. Louis-Noël Pouchet.
This course tells about the few specific methods to optimize the compiler.
In this course, I learnt about various loop transformation techniques like loop unrolling, strip-mining, tiling etc. which are done to optimize the code.  
It taught in detail about polyhedral computations and its reprentation.
The instructor taught tools like ISSC (compsys-tools.ens-lyon.fr/iscc/index.php) to calculate the data space and check the legality of the schedule. He also taught tools like PoCC PoCC - the Polyhedral Compiler Collection that converts the normal C progarm to its polyhedral form and Pluto which optimizes the parallelizes the polyhedral program generated by PoCC. 
During the course I completed 4 assignments which are decribed below:

Assignment 1: 
•	Implemented a C++ program for matrix multiplication
•	Timed the matrix multiplication kernel to find out the execution time of the program
•	Implemented loop transformations to optimize the program

Assignment 2:
•	Implemented an ISSC script to find out the iteration domains, access functions and dataspace of Jacobi 3D algorithm
•	Parameterized the data space to minimize the data reused between two consecutive iterations in order to find out a good tile size according to the data locality in the cache which would optimize the performance of Jacobi 3D kernel

Assignment 3: 
•	Optimized the matrix multiplication kernel used in assignment 1 using PoCC and Pluto tools
•	Implemented all permutations of loop transformations on the code generated by PoCC and Pluto to find out the minimum execution time
•	Automated the entire process by writing a python script that executes 20 different tile sizes along with different permutations of loop transformation and give the minimum execution time as the output
•	Extended the entire process on the heat-3D benchmark and found out its best execution time. 

Assignment 4:
•	Extended assignment 3 by taking the matrix multiplication code generated by PoCC and Pluto tool and converted it into a CUDA code
•	Implemented the CUDA code on a GPU and found its execution time and compared it with the best execution time of assignment 3 for matrix multiplication kernel.
